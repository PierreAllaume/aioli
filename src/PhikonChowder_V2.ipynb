{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcb271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from transformers import AutoModelForImageClassification\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "\n",
    "from Code_py import CustomMatrixDataset,CustomMatrixDataset_augmentation, BalancedBatchSampler\n",
    "from owkin_code import TorchTrainer, Chowder, auc2, slide_level_train_step, slide_level_val_step, get_cv_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893de009",
   "metadata": {},
   "source": [
    "### Import images/patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=\"5X\"\n",
    "path_to_images=f'E:\\\\01_DVLPMT_DATASET\\\\02_TILES_224\\\\**\\\\{res}\\\\*HES'\n",
    "patch_list=glob(path_to_images+'\\\\*')\n",
    "\n",
    "len(patch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function's aim is to extract the patient identifier (or slide identifier) from the path that leads to the image\n",
    "# It works by cutting the path, which is a chain of characters, at relevant symbols\n",
    "def get_patient_id_from_path(path):\n",
    "    patient=path.split('\\\\')[-1].split('[')[0][:-5]\n",
    "    return(str(patient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should load your image. It is paired with a function that is supposed to show this image, if it isn't working\n",
    "#there is probably an error with the 'load_image' function\n",
    "\n",
    "def load_image(path):\n",
    "    image=cv2.imread(path)\n",
    "    return(image)\n",
    "\n",
    "def show_image(image):\n",
    "    fig,ax=plt.subplots()\n",
    "    if image.shape[0] == 3:\n",
    "        image=image.permute({1,2,0})\n",
    "    ax.imshow(image)\n",
    "    return(fig)\n",
    "#show_image(load(image('path_to_one_of_your_image.tiff')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeba368",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=patch_list[20]\n",
    "print(get_patient_id_from_path(path))\n",
    "img=load_image(path)\n",
    "fig=show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll then create a dictionnary that will store every tile available for each patient\n",
    "whole_patient_dict={}\n",
    "for patch in patch_list: #Look through all the paths\n",
    "    patient=get_patient_id_from_path(patch)\n",
    "    if patient not in whole_patient_dict.keys(): #If it is the first time the patient pops up, create a new key that will be its list\n",
    "        whole_patient_dict[patient]=[]\n",
    "    whole_patient_dict[patient].append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228b037-22a7-498f-af40-06d6afc5edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(whole_patient_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78366311",
   "metadata": {},
   "source": [
    "#### Encoding those patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model pretrained by Owkin\n",
    "encoder = AutoModelForImageClassification.from_pretrained(\n",
    "    \"owkin/phikon\",\n",
    "    ignore_mismatched_sizes=False,\n",
    ")\n",
    "## Remove last layer, which is the classification layer for ImageNet (1000 features), we thus obtain 768 features\n",
    "encoder.classifier=torch.nn.Sequential()\n",
    "\n",
    "#Fix the GPU to work one, if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Set the model in evaluation mode, otherwise it will be trained and encoding will vary every time they are encoded\n",
    "encoder=encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc178ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every patch must be normalized. It is first reduced in the range [0,1], by dividing by 255 (highest possible value)\n",
    "# Then, as it is common in litterature, we normalize with the ImageNet values\n",
    "\n",
    "def normalize_image(tensor,mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]):\n",
    "    if tensor.shape[0] != 3:\n",
    "        tensor=tensor.permute(2,0,1)\n",
    "    norm_tens=torch.div(tensor, 255.0) #norm between 0 and 1\n",
    "    for k in range(3): #ImageNet norm\n",
    "        norm_tens[k,:,:]=torch.sub(norm_tens[k,:,:],mean[k])\n",
    "        norm_tens[k,:,:]=torch.div(norm_tens[k,:,:],std[k])\n",
    "    return(norm_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid loading every patch in memory, we'll iterate through the paths and encode patchs bit by bit\n",
    "# If you want to save the encodings to avoid re-encoding (and if you have room), indicate the save_path in the following function\n",
    "import os\n",
    "\n",
    "def encode_patch(path, encoder, save_path=None):\n",
    "    img=load_image(path)\n",
    "    encoded_patchs=[]\n",
    "    encoder=encoder.to(device)\n",
    "    tensor=normalize_image(torch.from_numpy(img).to(device))\n",
    "    tensor=tensor.unsqueeze(0) # Add a dimension to mimic a batch (but contains only one image)\n",
    "    enc=encoder(tensor)[0][0].clone().detach()\n",
    "        \n",
    "    if save_path != None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        patch_name=path.split('\\\\')[-1].split('.')[0]\n",
    "        torch.save(enc,save_path+'\\\\'+patch_name+'_enc.pt')\n",
    "    return(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95397525-c301-4b9a-8c12-180dc0e38e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file=\"E:\\\\01_DVLPMT_DATASET\\\\labels_402.csv\"\n",
    "labels=pd.read_csv(label_file, delimiter=\";\")\n",
    "labels['patient_id'] = labels['patient_id'].astype(str)\n",
    "\n",
    "nb_classes=len(set(list(labels['label'])))\n",
    "print('Classification for',nb_classes,'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4f8a1-315d-4541-8e2d-89388b38b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To add ID and FOLD column\n",
    "labels=labels.sort_values('label').reset_index().drop(['index'],axis=1)\n",
    "nb_0, nb_1=labels.groupby('label').count().values\n",
    "list_0, list_1= [], []\n",
    "for i in range(int(nb_0)):\n",
    "    list_0.append(i%5)\n",
    "for j in range(int(nb_1)):\n",
    "    list_1.append(j%5)\n",
    "new_col={'fold':list_0+list_1, 'ID':np.arange(len(labels))}\n",
    "new_labels=pd.concat([labels,pd.DataFrame.from_dict(new_col)],axis=1)\n",
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5f4eb-5826-4745-b683-868a416a7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list=[]\n",
    "for patient in whole_patient_dict.keys():\n",
    "    len_list.append(len(whole_patient_dict[patient]))\n",
    "mini=min(len_list)\n",
    "\n",
    "print('Your minimum number of patches is',mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad52a3-bcf7-4bc6-bcc3-938f0452e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_patch=mini-1\n",
    "patient_dict={}\n",
    "removed=0\n",
    "for patient in whole_patient_dict.keys():\n",
    "    if len(whole_patient_dict[patient])>nb_patch:\n",
    "        patient_dict[patient]=whole_patient_dict[patient]\n",
    "    else:\n",
    "        removed+=1\n",
    "print('You removed', removed, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a new dictionnary, for each patient, instead of being the list of paths, it will be the list of encoded tiles\n",
    "def create_patient_encoded_dict(patient_dict, encoder, patch_tiling_infos=None, save_path=None, is_saved=None):\n",
    "    if is_saved !=None:\n",
    "        print('Loading patient dict')\n",
    "        patient_encoded=torch.load(is_saved)\n",
    "    else:\n",
    "        patient_encoded={}\n",
    "        progress_bar = tqdm.tqdm(total=np.sum([len(patient_dict[patient]) for patient in list(patient_dict.keys())]), position=0,\n",
    "                                 desc=\"Processing\")\n",
    "        for i,patient in enumerate(list(patient_dict.keys())):\n",
    "            progress_bar.set_description(\"Processing patient {}/{}\".format(i+1,len(patient_dict)))\n",
    "            tile_list=patient_dict[patient]\n",
    "            patient_encoded[patient]=[]\n",
    "            \n",
    "            for tile_path in tile_list:\n",
    "                patient_encoded[patient].append(encode_patch(tile_path,encoder,save_path=save_path))\n",
    "                                \n",
    "            progress_bar.update(1)\n",
    "        \n",
    "    return(patient_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ecba1c-a1c6-4cba-b828-909956919116",
   "metadata": {},
   "source": [
    "patient_encoded=create_patient_encoded_dict(patient_dict, encoder, \n",
    "                patch_tiling_infos=None, save_path=\"D:\\\\02_TILES\\\\004_encoded\\\\5X\", is_saved=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de43361-4f91-47f2-b128-9f56bf7fb85b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "patient_list=list(patient_encoded.keys())\n",
    "random.shuffle(patient_list) # C'est ici qu'il faut juste appeler la fonction shuffle, sans l'attribuer à une variable avec un =\n",
    "patient_encoded_shuffled={}\n",
    "for patient in patient_list:\n",
    "    patient_encoded_shuffled[patient]=patient_encoded[patient]\n",
    "del patient_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543172b7-b961-4449-9967-55684ce61351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(patient_encoded_shuffled, f\"E:\\\\02_TILES\\\\004_encoded\\\\{res}_patient_dict_shuffle.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798f3a1-3924-4a82-9623-ae915cefee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a loading of encoded dict\n",
    "patient_encoded=create_patient_encoded_dict(patient_dict, encoder, save_path=None, is_saved=f\"E:\\\\01_DVLPMT_DATASET\\\\03_TILES_ENC_PHIKON\\\\{res}_patient_dict_shuffle_402.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomMatrixDataset(Dataset):\n",
    "    def __init__(self, patient_dict, labels, nb_patch, fixed=False):\n",
    "        self.mat_dict = patient_dict\n",
    "        self.nb_patch=nb_patch\n",
    "        self.labels=labels\n",
    "        self.fixed=fixed\n",
    "        if self.fixed:\n",
    "            self.patch_per_patient={}\n",
    "    \n",
    "    def random_patch_selection(self, patch_list, slide):\n",
    "        if len(patch_list) >= self.nb_patch:\n",
    "            patch_sel=random.sample(patch_list, self.nb_patch)\n",
    "        else:\n",
    "            patch_sel=patch_list\n",
    "            n=self.nb_patch-len(patch_list)\n",
    "            while n>len(patch_list):\n",
    "                patch_sel.extend(patch_list)\n",
    "                n-=len(patch_list)\n",
    "            last_patch_sel=random.sample(patch_list, n)\n",
    "            patch_sel.extend(last_patch_sel)\n",
    "        if self.fixed:\n",
    "            self.patch_per_patient[slide]=patch_sel\n",
    "        return(patch_sel)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mat_dict)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        slide=self.labels.loc[self.labels['ID']==idx]['patient_id'].iloc[0]\n",
    "        patch_list = self.mat_dict[slide]\n",
    "        label = torch.tensor(self.labels.loc[self.labels['patient_id'] == slide]['label'].iloc[0]).to(torch.int64)\n",
    "        \n",
    "        if self.fixed:\n",
    "            if slide in self.patch_per_patient.keys():\n",
    "                patch_sel=patch_per_patient[slide]\n",
    "            else:\n",
    "                patch_sel=self.random_patch_selection(patch_list, slide)\n",
    "        else:\n",
    "            patch_sel=self.random_patch_selection(patch_list, slide)\n",
    "        \n",
    "        return torch.stack(patch_sel), label            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5cb888-a236-4899-95e8-d9285853513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds=CustomMatrixDataset(patient_encoded, new_labels, nb_patch=mini, fixed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b84aa-cd20-4308-bfac-1f82af718975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the loss function, optimizer and metrics for the training\n",
    "#if nb_classes==2:\n",
    "#    criterion = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "#else:\n",
    "criterion = torch.nn.CrossEntropyLoss()  #Cross-Entropy Loss\n",
    "    \n",
    "optimizer = torch.optim.Adam              # Adam optimizer\n",
    "metrics = {\"auc\": auc2}                    # AUC will be the tracking metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b31a01-b20f-4737-8cba-7bc1c1b8c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from trainer import TorchTrainer, slide_level_train_step, slide_level_val_step\n",
    "\n",
    "# We run a 5-fold cross-validation with 1 repeat (you can tweak these parameters)\n",
    "n_outer_cv = 5\n",
    "n_inner_cv = 4\n",
    "train_metrics, val_metrics = [], []\n",
    "train_losses, val_losses = [], []\n",
    "test_logits = []\n",
    "\n",
    "cv_start_time = datetime.now()\n",
    "\n",
    "chowder = Chowder(\n",
    "    in_features=768,                     # output dimension of Phikon\n",
    "    out_features=nb_classes,                      # dimension of predictions (a probability for class \"1\")\n",
    "    n_top=5,                             # number of top scores in Chowder \n",
    "    n_bottom=5,                          # number of bottom scores in Chowder\n",
    "    mlp_hidden=[200, 100],               # MLP hidden layers after the max-min layer\n",
    "    mlp_activation=torch.nn.Sigmoid(),   # MLP activation\n",
    "    bias=True                            # bias for first 1D convolution which computes scores\n",
    ")\n",
    "\n",
    "best_model_inner_cv={}\n",
    "\n",
    "for test_fold in range(n_outer_cv):\n",
    "    best_model_inner_cv[test_fold]={}\n",
    "    print(f\"Running cross-validation #{test_fold+1}\")\n",
    "    # We stratify with respect to the training labels\n",
    "    test_idx=list(new_labels[new_labels['fold']==test_fold]['ID'])\n",
    "    test_set = torch.utils.data.Subset(whole_ds, test_idx)\n",
    "\n",
    "    test_lab=[]\n",
    "    for i in range(len(test_set)):\n",
    "        test_lab.append(test_set[i][1])\n",
    "    \n",
    "    cv_splits=[]\n",
    "    for j in range(n_inner_cv):\n",
    "        val_fold=j if j<test_fold else j+1\n",
    "        val_idx=list(new_labels[new_labels['fold']==val_fold]['ID'])\n",
    "        train_idx=list(new_labels[(new_labels['fold']!=test_fold) & (new_labels['fold']!=val_fold)]['ID'])\n",
    "        cv_splits.append((train_idx,val_idx))\n",
    "\n",
    "    for i, (train_indices, val_indices) in enumerate(cv_splits):\n",
    "        fold_start_time = datetime.now()\n",
    "        trainer_2 = TorchTrainer(\n",
    "            model=deepcopy(chowder),\n",
    "            criterion=criterion,\n",
    "            metrics=metrics,\n",
    "            batch_size=64,                           # you can tweak this\n",
    "            num_epochs=100,                           # you can tweak this\n",
    "            learning_rate=1e-3,                      # you can tweak this\n",
    "            weight_decay=0.0,                        # you can tweak this\n",
    "            device=device,\n",
    "            balanced=True,                           #you can tweak this\n",
    "            num_workers=0, \n",
    "            optimizer=deepcopy(optimizer),\n",
    "            train_step=slide_level_train_step,\n",
    "            val_step=slide_level_val_step,\n",
    "            nb_classes=nb_classes\n",
    "        )\n",
    "\n",
    "        print(f\"Running cross-validation on split #{i+1}\")\n",
    "        train_train_dataset = torch.utils.data.Subset(\n",
    "            whole_ds, indices=train_indices\n",
    "        )\n",
    "        train_val_dataset = torch.utils.data.Subset(\n",
    "            whole_ds, indices=val_indices\n",
    "        )\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            # Training step for the given number of epochs\n",
    "            local_train_metrics, local_val_metrics, local_train_losses, local_val_losses = trainer_2.train(\n",
    "                train_train_dataset, train_val_dataset\n",
    "            )\n",
    "            # Predictions on test (logits, sigmoid(logits) = probability)\n",
    "            local_test_logits = trainer_2.predict(test_set)[1]\n",
    "\n",
    "        train_metrics.append(local_train_metrics)\n",
    "        val_metrics.append(local_val_metrics)\n",
    "        train_losses.append(local_train_losses)\n",
    "        val_losses.append(local_val_losses)\n",
    "        test_logits.append(local_test_logits)\n",
    "        fold_end_time = datetime.now()\n",
    "        fold_running_time = fold_end_time - fold_start_time\n",
    "        best_model_inner_cv[test_fold][i]=trainer_2.best_sd\n",
    "        print(\"\\n-----------------------------Finished in {}---------------------------------------\\n\".format(fold_running_time))\n",
    "    clear_output()\n",
    "cv_end_time = datetime.now()\n",
    "\n",
    "cv_running_time = cv_end_time - cv_start_time\n",
    "print(\"\\nFinished cross-validation in {}\".format(cv_running_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd847e1-d3fb-4dc9-80f9-e8794343508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your model\n",
    "#torch.save(trainer_2.model, 'E:\\\\04_RETURN_TO_TILES\\\\MODEL_TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb59c35-e0de-422c-ac69-82c9b4c86faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot your losses\n",
    "figure,axs=plt.subplots(ncols=n_outer_cv,nrows=n_inner_cv, figsize=(10*n_outer_cv,5*n_inner_cv))\n",
    "X=np.arange(trainer_2.num_epochs)\n",
    "for j in range(n_outer_cv):\n",
    "    for i in range(n_inner_cv):\n",
    "        if n_outer_cv==1:\n",
    "            ax=axs[i]\n",
    "        else:\n",
    "            ax=axs[i,j]\n",
    "        \n",
    "        Y_train=train_losses[j*n_inner_cv+i]\n",
    "        Y_val=val_losses[j*n_inner_cv+i]\n",
    "        ax.plot(X,Y_train, label='train_loss')\n",
    "        ax.plot(X,Y_val, label='val_loss')\n",
    "        if i==0:\n",
    "            ax.title.set_text('Repeat '+str(j+1))\n",
    "        if j==0:\n",
    "            ax.set_ylabel('Fold '+ str(i+1), rotation=0, labelpad=20)\n",
    "        ax.legend(loc='lower left')\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52090e56-249a-4d1f-b650-8204be1896d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate your model\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create subplots for confusion matrices\n",
    "fig, axs_cm = plt.subplots(1, n_outer_cv, figsize=(15, 10))\n",
    "\n",
    "# To store true labels and predicted probabilities for ROC curve and Se Sp\n",
    "roc_data = {'true_labels': [], 'probas': []}\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "best_model_outer_cv={}\n",
    "for test_fold in tqdm.tqdm(range(n_outer_cv)):\n",
    "    test_idx=list(new_labels[new_labels['fold']==test_fold]['ID'])\n",
    "    test_set = torch.utils.data.Subset(whole_ds, test_idx)\n",
    "    test_dl = DataLoader(test_set)\n",
    "    \n",
    "    best_f1=0\n",
    "    \n",
    "    for val_fold in range(n_inner_cv):\n",
    "        model_test=deepcopy(trainer_2.model)\n",
    "        model_test.load_state_dict(best_model_inner_cv[test_fold][val_fold])\n",
    "        true_lab=[]\n",
    "        logits=[]\n",
    "        with torch.no_grad():\n",
    "            model_test=model_test.eval()\n",
    "            model_test=model_test.to(device)\n",
    "            for batch in test_dl:\n",
    "                matrix, lab = batch\n",
    "                matrix = matrix.to(device)\n",
    "                true_lab.append(lab)\n",
    "                logits.append(model_test(matrix).squeeze(1))\n",
    "\n",
    "            probas=torch.nn.functional.softmax(torch.stack(logits).squeeze(1), dim=1).to('cpu')\n",
    "            preds=torch.argmax(probas,1)\n",
    "\n",
    "            test_f1=f1_score(np.array(preds), np.array(torch.stack(true_lab)), average='macro')\n",
    "            if test_f1 > best_f1:\n",
    "                best_f1=test_f1\n",
    "                best_model_outer_cv[test_fold]=(best_model_inner_cv[test_fold][val_fold], preds)\n",
    "\n",
    "    # Concatenate all true labels and predictions\n",
    "    true_lab = torch.cat(true_lab).numpy()  # Flatten to a 1D array\n",
    "    preds = best_model_outer_cv[test_fold][1].numpy()\n",
    "\n",
    "    if len(true_lab) == len(preds):  # Ensure lengths match before computing the confusion matrix\n",
    "        # Compute confusion matrix\n",
    "        test_cm = confusion_matrix(true_lab, preds)\n",
    "        \n",
    "        # Extract TP, TN, FP, FN from confusion matrix\n",
    "        TN, FP, FN, TP = test_cm.ravel()\n",
    "\n",
    "        # Compute Sensitivity (Recall) and Specificity\n",
    "        sensitivity = TP / (TP + FN)  # True Positive Rate (Recall)\n",
    "        specificity = TN / (TN + FP)  # True Negative Rate (Specificity)\n",
    "\n",
    "        # Store Sensitivity and Specificity for this fold\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        specificity_scores.append(specificity)\n",
    "\n",
    "        # Plot confusion matrix on the first row\n",
    "        disp = ConfusionMatrixDisplay(test_cm)\n",
    "        disp.plot(ax=axs_cm[test_fold], colorbar=False)\n",
    "        axs_cm[test_fold].set_title(f'F1: {best_f1:.3f}')\n",
    "\n",
    "        # Store data for ROC curve plotting later\n",
    "        roc_data['true_labels'].append(true_lab)\n",
    "        roc_data['probas'].append(probas.numpy())  # Store probabilities for AUC calculation\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: True labels and predictions length mismatch for fold {test_fold}\")\n",
    "\n",
    "# Display the confusion matrices plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(\"confusion_matrices.png\", dpi=300)  # Save the confusion matrix with 300 DPI to the working directory, default is desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24974289-9973-44bb-af1e-f4330830a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results for Sensitivity and Specificity\n",
    "print(\"\\nSensitivity and Specificity for each fold:\")\n",
    "for i in range(n_outer_cv):\n",
    "    print(f\"Fold {i}: Sensitivity = {sensitivity_scores[i]:.3f}, Specificity = {specificity_scores[i]:.3f}\")\n",
    "\n",
    "# Calculate and print the mean and standard deviation of Sensitivity and Specificity\n",
    "mean_sensitivity = np.mean(sensitivity_scores)\n",
    "std_sensitivity = np.std(sensitivity_scores)\n",
    "mean_specificity = np.mean(specificity_scores)\n",
    "std_specificity = np.std(specificity_scores)\n",
    "\n",
    "print(f\"\\nSummary on internal dataset:\")\n",
    "print(f\"Mean Sensitivity: {mean_sensitivity:.3f} ± {std_sensitivity:.3f}\")\n",
    "print(f\"Mean Specificity: {mean_specificity:.3f} ± {std_specificity:.3f}\")\n",
    "\n",
    "#calculate meand+-sd F1 Score\n",
    "f1_scores = [0.831, 0.899, 0.897, 0.883, 0.909]\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "print(f\"Mean F1 Score: {mean_f1:.3f} ± {std_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6976561-d61b-4033-be5b-5120fca9b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# List to store AUC for each fold\n",
    "auc_scores = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Create a figure for all ROC curves on the same plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Loop over stored ROC data and plot all ROC curves on the same plot\n",
    "for test_fold in range(n_outer_cv):\n",
    "    true_labels = roc_data['true_labels'][test_fold]\n",
    "    probas = roc_data['probas'][test_fold]\n",
    "    \n",
    "    # Calculate ROC curve for this fold\n",
    "    fpr, tpr, _ = roc_curve(true_labels, probas[:, 1])  # Get ROC curve values for the positive class (class 1)\n",
    "    \n",
    "    # Interpolate the TPR (True Positive Rate) to a common set of FPR values (mean_fpr)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0  # Ensure the curve starts at (0,0)\n",
    "    tprs.append(interp_tpr)\n",
    "    \n",
    "    # Calculate AUC for this fold and store it\n",
    "    auc_score = roc_auc_score(true_labels, probas[:, 1])  # AUC for binary classification\n",
    "    auc_scores.append(auc_score)\n",
    "    \n",
    "    # Use RocCurveDisplay to plot ROC curve for this fold\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score).plot(ax=ax, alpha=0.3, lw=1, label=f'Fold {test_fold} (AUC: {auc_score:.3f})')\n",
    "\n",
    "# Plot the diagonal (chance level)\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"grey\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "# Calculate the mean ROC curve\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0  # Ensure the curve ends at (1, 1)\n",
    "\n",
    "# Calculate the mean AUC\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "# Calculate the standard deviation of the AUC\n",
    "std_auc = np.std(auc_scores)\n",
    "\n",
    "# Plot the mean ROC curve\n",
    "ax.plot(mean_fpr, mean_tpr, color=\"b\", label=f'Mean ROC (AUC = {mean_auc:.2f} ± {std_auc:.2f})', lw=2, alpha=0.8)\n",
    "\n",
    "# Calculate the standard deviation of the TPRs (True Positive Rates)\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "\n",
    "# Create shaded area for the std deviation\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color=\"grey\", alpha=0.2, label=r\"$\\pm$ 1 std. dev.\")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the mean and standard deviation of the AUC scores\n",
    "print(f\"Mean AUC: {mean_auc:.3f} ± {std_auc:.3f}\")\n",
    "\n",
    "#fig.savefig(\"roc_curves_all.png\", dpi=300)  # Save the confusion matrix with 300 DPI to the working directory, default is desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240ce3d-e323-4af0-abc1-91f52ab1faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the external validation dataset\n",
    "external_encoded=torch.load(\"E:\\\\03_PROSPECTIV2025_DATASET\\\\5X_patient_dict_shuffle_prospectiv2025.pt\")\n",
    "external_label=pd.read_csv(\"E:\\\\03_PROSPECTIV2025_DATASET\\\\labels_prospectiv2025.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c66a5-fd37-44fb-90a3-d22fd9c49e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found=external_label[~external_label['patient_id'].isin(list(external_encoded.keys()))]\n",
    "external_label=external_label[external_label['patient_id'].isin(list(external_encoded.keys()))]\n",
    "\n",
    "external_label=external_label.sort_values('label').reset_index().drop(['index'],axis=1)\n",
    "nb_0, nb_1=external_label.groupby('label').count().values\n",
    "list_0, list_1= [], []\n",
    "for i in range(int(nb_0)):\n",
    "    list_0.append(i%5)\n",
    "for j in range(int(nb_1)):\n",
    "    list_1.append(j%5)\n",
    "new_col={'fold':list_0+list_1, 'ID':np.arange(len(external_label))}\n",
    "new_external_label=pd.concat([external_label,pd.DataFrame.from_dict(new_col)],axis=1)\n",
    "new_external_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df4bd8-5a6c-4a76-9969-b101484d6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMatrixDataset(Dataset):\n",
    "    def __init__(self, patient_dict, labels, nb_patch, fixed=False, all_patchs=True):\n",
    "        self.mat_dict = patient_dict\n",
    "        self.nb_patch=nb_patch\n",
    "        self.labels=labels\n",
    "        self.fixed=fixed\n",
    "        self.all_patchs=all_patchs\n",
    "        if self.fixed:\n",
    "            self.patch_per_patient={}\n",
    "    \n",
    "    def random_patch_selection(self, patch_list, slide):\n",
    "        if len(patch_list) >= seff.nb_patch:\n",
    "            patch_sel=random.sample(patch_list, self.nb_patch)\n",
    "        else:\n",
    "            patch_sel=patch_list\n",
    "            n=self.nb_patch-len(patch_list)\n",
    "            while n>len(patch_list):\n",
    "                patch_sel.extend(patch_list)\n",
    "                n-=len(patch_list)\n",
    "            last_patch_sel=random.sample(patch_list, n)\n",
    "            patch_sel.extend(last_patch_sel)\n",
    "        if fixed:\n",
    "            self.patch_per_patient[slide]=patch_sel\n",
    "        return(patch_sel)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mat_dict)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        slide=self.labels.loc[self.labels['ID']==idx]['patient_id'].iloc[0]\n",
    "        patch_list = self.mat_dict[slide]\n",
    "        label = torch.tensor(self.labels.loc[self.labels['patient_id'] == slide]['label'].iloc[0]).to(torch.int64)\n",
    "        \n",
    "        if self.all_patchs:\n",
    "            return torch.stack(patch_list), label\n",
    "        \n",
    "        if self.fixed:\n",
    "            if slide in self.patch_per_patient.keys():\n",
    "                patch_sel=patch_per_patient[slide]\n",
    "            else:\n",
    "                patch_sel=random_patch_selection(patch_list, slide)\n",
    "        else:\n",
    "            patch_sel=random_patch_selection(patch_list, slide)\n",
    "        \n",
    "        return torch.stack(patch_sel), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50da451-58af-42d7-9df2-c03f20eb68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "fig, axs = plt.subplots(1, n_outer_cv, figsize=(15, 10))\n",
    "\n",
    "# Prepare external dataset\n",
    "external_ds = CustomMatrixDataset(external_encoded, new_external_label, nb_patch=20, fixed=False, all_patchs=True)\n",
    "external_dl = DataLoader(external_ds)\n",
    "\n",
    "all_preds = {}\n",
    "all_probas = {}\n",
    "true_labels = [] \n",
    "auc_scores = {}  \n",
    "\n",
    "for test_fold in best_model_outer_cv.keys():\n",
    "    # Load the best model for this fold\n",
    "    model_best = deepcopy(trainer_2.model)\n",
    "    model_best.load_state_dict(best_model_outer_cv[test_fold][0])\n",
    "    model_best = model_best.eval().to(device)\n",
    "\n",
    "    logits, probas_list, true_lab = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in external_dl:\n",
    "            matrix, lab = batch\n",
    "            matrix = matrix.to(device)\n",
    "            logits.append(model_best(matrix).squeeze(1))  # Store model outputs\n",
    "            true_lab.append(lab)  # Store true labels\n",
    "\n",
    "    # Convert lists to tensors and move to CPU\n",
    "    probas = torch.nn.functional.softmax(torch.cat(logits), dim=1).cpu().numpy()  # Get softmax probabilities\n",
    "    preds = np.argmax(probas, axis=1)  # Get predicted labels\n",
    "    true_lab = torch.cat(true_lab).cpu().numpy()  # Flatten true labels\n",
    "\n",
    "    # Store predictions and probabilities\n",
    "    all_preds[test_fold] = preds\n",
    "    all_probas[test_fold] = probas  # Store softmax scores\n",
    "\n",
    "    # Compute F1 score per fold\n",
    "    ext_f1 = f1_score(true_lab, preds, average='macro')\n",
    "    \n",
    "    # Compute AUC per fold\n",
    "    auc_scores[test_fold] = roc_auc_score(true_lab, probas[:, 1])  # AUC for class 1\n",
    "\n",
    "    # Compute and plot confusion matrix for each fold model\n",
    "    ext_cm = confusion_matrix(true_lab, preds)\n",
    "    disp_ext = ConfusionMatrixDisplay(ext_cm)\n",
    "    disp_ext.plot(ax=axs[test_fold], colorbar=False)\n",
    "    axs[test_fold].set_title(f'Fold {test_fold} F1 = {ext_f1:.3f}')\n",
    "\n",
    "    # Store true labels\n",
    "    if len(true_labels) == 0:\n",
    "        true_labels = true_lab\n",
    "\n",
    "# Majority voting across folds for final prediction\n",
    "nb_pat = len(next(iter(all_preds.values())))  # Number of samples\n",
    "pred_voting = []\n",
    "\n",
    "for pat in range(nb_pat):\n",
    "    pat_votes = [all_preds[fold][pat] for fold in all_preds.keys()]\n",
    "    majority_vote = Counter(pat_votes).most_common(1)[0][0]  # Get majority class\n",
    "    pred_voting.append(majority_vote)\n",
    "\n",
    "# Compute final voting F1 score\n",
    "voting_f1 = f1_score(true_labels, np.array(pred_voting), average='macro')\n",
    "print('Voting F1 =', voting_f1)\n",
    "\n",
    "# Compute final AUC for voting model (average softmax probabilities)\n",
    "avg_probas = np.mean(np.array([all_probas[fold] for fold in all_probas]), axis=0)  # Averaging across folds\n",
    "voting_auc = roc_auc_score(true_labels, avg_probas[:, 1])  # AUC for class 1\n",
    "\n",
    "print('Voting AUC =', voting_auc)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195e9b0-fb70-47fd-82a3-e05697e05541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for the final voting predictions\n",
    "voting_cm = confusion_matrix(true_labels, np.array(pred_voting))\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=voting_cm, display_labels=[0, 1])\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=True)\n",
    "\n",
    "# Extract TP, TN, FP, FN\n",
    "TN, FP, FN, TP = voting_cm.ravel()\n",
    "\n",
    "# Compute Sensitivity (Se) and Specificity (Sp)\n",
    "Se = TP / (TP + FN)  # Sensitivity / Recall\n",
    "Sp = TN / (TN + FP)  # Specificity\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title(f'Voting Confusion Matrix (F1 = {voting_f1:.3f})')\n",
    "plt.show()\n",
    "\n",
    "print(f'Sensitivity (Se): {Se:.3f}')\n",
    "print(f'Specificity (Sp): {Sp:.3f}')\n",
    "\n",
    "#fig.savefig(\"voting_confusion_matrices.png\", dpi=300)  # Save the confusion matrix with 300 DPI to the working directory, default is desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c65a3-b14f-48cc-b46c-140c598a7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Define a set of distinct but subdued colors\n",
    "fold_colors = ['lightblue', 'lightcoral', 'lightgreen', 'lightskyblue', 'lightsalmon']\n",
    "\n",
    "# Plot ROC curve for each fold model with distinct subdued colors\n",
    "for i, test_fold in enumerate(best_model_outer_cv.keys()):\n",
    "    fpr, tpr, _ = roc_curve(true_labels, all_probas[test_fold][:, 1])  # FPR, TPR for fold model\n",
    "    roc_auc = auc(fpr, tpr)  # Compute AUC\n",
    "    plt.plot(fpr, tpr, color=fold_colors[i], alpha=0.8, label=f'Fold {test_fold} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Compute ROC curve for the final voting model\n",
    "avg_probas = np.mean(np.array([all_probas[fold] for fold in all_probas]), axis=0)  # Average softmax scores\n",
    "fpr_voting, tpr_voting, _ = roc_curve(true_labels, avg_probas[:, 1])  # FPR, TPR for voting model\n",
    "roc_auc_voting = auc(fpr_voting, tpr_voting)\n",
    "\n",
    "# Plot ROC curve for the voting model (bold black)\n",
    "plt.plot(fpr_voting, tpr_voting, color='black', linewidth=3, label=f'Voting Model (AUC = {roc_auc_voting:.3f})')\n",
    "\n",
    "# Plot diagonal reference line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curves for Each Fold and Voting Model')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Remove grid background\n",
    "plt.grid(False)\n",
    "\n",
    "#plt.savefig(\"roc_curve.png\", dpi=300, bbox_inches='tight') \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4e36b-c6b6-42b8-8e4c-adeb0b680028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve patient IDs and ground truth\n",
    "patient_ids = new_external_label['patient_id'].values  \n",
    "final_true = np.array(true_labels)\n",
    "\n",
    "# Collect fold predictions into a DataFrame\n",
    "fold_preds = {\n",
    "    f\"fold_{fold}_pred\": all_preds[fold] for fold in all_preds.keys()\n",
    "}\n",
    "fold_preds_df = pd.DataFrame(fold_preds)\n",
    "\n",
    "# Build final results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"patient_id\": patient_ids,\n",
    "    \"ground_truth\": final_true\n",
    "})\n",
    "\n",
    "# Concatenate fold predictions\n",
    "results_df = pd.concat([results_df, fold_preds_df], axis=1)\n",
    "\n",
    "# Add majority voting predictions\n",
    "results_df[\"voting_pred\"] = np.array(pred_voting)\n",
    "\n",
    "# Add averaged probability for class 1\n",
    "results_df[\"avg_proba_class1\"] = avg_probas[:, 1]\n",
    "\n",
    "# Show full table\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(results_df)\n",
    "\n",
    "# Optionally save to CSV for external inspection\n",
    "#results_df.to_csv(\"external_validation_predictions_with_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df4978-5419-4faa-8c68-7effcb05bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "results_df.boxplot(column=\"avg_proba_class1\", by=\"ground_truth\")\n",
    "plt.axhline(0.5, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Ground Truth Class\")\n",
    "plt.ylabel(\"Average probability for class 1\")\n",
    "plt.title(\"Distribution of avg_proba_class1 by True Class\")\n",
    "plt.suptitle(\"\")  # remove default pandas title\n",
    "\n",
    "#plt.savefig(\"BoxplotDistributionperClassEVC.png\", dpi=300, bbox_inches='tight') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41c5c7-9c09-4501-bfd3-618e0c788f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(results_df[\"avg_proba_class1\"], bins=20, edgecolor=\"black\", alpha=0.7)\n",
    "plt.axvline(0.5, color=\"red\", linestyle=\"--\", label=\"Decision threshold (0.5)\")\n",
    "plt.xlabel(\"Average probability for class 1\")\n",
    "plt.ylabel(\"Number of patients\")\n",
    "plt.title(\"Distribution of avg_proba_class1 across patients\")\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"HistogramDistributionperAvgProbEVC.png\", dpi=300, bbox_inches='tight') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14cef0-67c8-432e-bfeb-76a860768948",
   "metadata": {},
   "source": [
    "### Retour aux tuiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c4de2-7797-41dd-b3d0-ef81264c5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model architecture and weights\n",
    "model_path = 'E:/04_RETURN_TO_TILES/MODEL_TEST_5X'\n",
    "chowder_model = torch.load(model_path)\n",
    "\n",
    "# Recreate the model architecture\n",
    "chowder_tiles = Chowder(\n",
    "    in_features=768,\n",
    "    out_features=chowder_model.mlp[2].out_features,\n",
    "    n_top=chowder_model.extreme_layer.n_top,\n",
    "    n_bottom=chowder_model.extreme_layer.n_bottom,\n",
    "    return_indices=True,\n",
    "    mlp_hidden=[\n",
    "        chowder_model.mlp[0][0].out_features,\n",
    "        chowder_model.mlp[1][0].out_features\n",
    "    ],\n",
    "    mlp_activation=torch.nn.Sigmoid(),\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "# Load trained weights from CV\n",
    "test_fold = 4\n",
    "chowder_tiles.load_state_dict(best_model_outer_cv[test_fold][0])\n",
    "chowder_tiles.eval()\n",
    "chowder_tiles.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534445b-986c-4276-895b-3857cb336c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = list(new_labels[new_labels['fold'] == test_fold]['patient_id'])\n",
    "patient_pred = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for patient_id in tqdm.tqdm(test_patients):\n",
    "        tensor = torch.stack(patient_encoded[patient_id]).to(device)\n",
    "        x = tensor.unsqueeze(0)  # Shape: (1, n_tiles, 768)\n",
    "        \n",
    "        pred_logits, indices = chowder_tiles(x)\n",
    "        pred = pred_logits[0][0].cpu()\n",
    "        indices = indices.squeeze().cpu()\n",
    "\n",
    "        proba = torch.nn.functional.softmax(pred, dim=-1)\n",
    "\n",
    "        patient_pred[patient_id] = {\n",
    "            'proba': proba,\n",
    "            'pred': int(torch.argmax(proba)),\n",
    "            'indices': indices\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd5433-d443-411f-980c-08b90bf315c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patches = {\n",
    "    pid: [patient_dict[pid][idx] for idx in patient_pred[pid]['indices']]\n",
    "    for pid in patient_pred\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ba573-dd6b-48cd-b6bb-63c8b055518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_feature(path, res, clss):\n",
    "    color = [0, 0, 255] if clss == 'top' else [128, 0, 0]\n",
    "    x = int(path.split('x=')[-1].split(',')[0])\n",
    "    y = int(path.split('y=')[-1].split(',')[0])\n",
    "\n",
    "    scale = {'20X': 2, '10X': 4, '5X': 8}[res]\n",
    "    sq_size = 224 * scale\n",
    "\n",
    "    coords = [[[x, y], [x + sq_size, y], [x + sq_size, y + sq_size], [x, y + sq_size], [x, y]]]\n",
    "\n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\"type\": \"Polygon\", \"coordinates\": coords},\n",
    "        \"properties\": {\n",
    "            \"objectType\": \"annotation\",\n",
    "            \"classification\": {\"name\": clss, \"color\": color}\n",
    "        }\n",
    "    }\n",
    "\n",
    "def export_geojson(patient_patches, res, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for patient_id, paths in patient_patches.items():\n",
    "        features = [\n",
    "            new_feature(p, res, 'top' if i < chowder_model.extreme_layer.n_top else 'bottom')\n",
    "            for i, p in enumerate(paths)\n",
    "        ]\n",
    "\n",
    "        geo_json = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "        out_path = os.path.join(output_dir, f\"{patient_id}_annot.json\")\n",
    "        \n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(geo_json, f, indent=2)\n",
    "\n",
    "# Usage\n",
    "res = \"5X\"\n",
    "geojson_output_dir = f\"E:/04_RETURN_TO_TILES/predictive_patches_coords_{res}/\"\n",
    "export_geojson(patient_patches, res, geojson_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1fb30-8e61-4c63-b796-2fc55eb7e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col = model_test.extreme_layer.n_top + model_test.extreme_layer.n_bottom\n",
    "fig, axs = plt.subplots(nrows=len(patient_patches), ncols=n_col + 1, figsize=(n_col + 1, (n_col + 1)*5))\n",
    "plt.subplots_adjust(left=0.05, bottom=0.1, right=0.98, top=0.975, wspace=0.05, hspace=0.3)\n",
    "\n",
    "for i, key in enumerate(patient_patches.keys()):\n",
    "    patch_list = patient_patches[key]\n",
    "    true_label = labels[labels[\"patient_id\"] == key][\"label\"].iloc[0]\n",
    "    pred_label = patient_pred[key][\"pred\"]\n",
    "    confidence = patient_pred[key].get(\"confidence\", None)\n",
    "\n",
    "    correct = (true_label == pred_label)\n",
    "    color = \"green\" if correct else \"red\"\n",
    "\n",
    "    label_str = f'Patient {key}\\nTrue {true_label} | Pred {pred_label}'\n",
    "    if confidence is not None:\n",
    "        label_str += f'\\nConf: {confidence:.2f}'\n",
    "\n",
    "    # First column for text label only\n",
    "    axs[i, 0].axis(\"off\")  # Turn off the label cell's axis\n",
    "    axs[i, 0].text(-0.05, 0.5, label_str, va='center', ha='right', fontsize=10, color=color, transform=axs[i, 0].transAxes)\n",
    "\n",
    "    # Remaining columns: display tiles\n",
    "    for j in range(n_col):\n",
    "        ax = axs[i, j + 1]\n",
    "        ax.imshow(load_image(patch_list[j]))\n",
    "        ax.tick_params(left=False, right=False, labelleft=False,\n",
    "                       labelbottom=False, bottom=False)\n",
    "\n",
    "# Add vertical dashed line (now shifted one column right)\n",
    "split = model_test.extreme_layer.n_top\n",
    "line_x = (split + 1.2) / (n_col + 1)  # Account for added column\n",
    "line = plt.Line2D((line_x, line_x), (.1, .975), linestyle='--', color='red', transform=fig.transFigure)\n",
    "fig.add_artist(line)\n",
    "\n",
    "fig.suptitle('Patches selected to predict, top 5 on the left, bottom 5 on the right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a28f0-9e85-4480-bc03-5400cf68b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('predicted_tiles_fold_4', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa176035-9b97-4aed-a4be-09a11f8d5e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
